{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "13cae313-6ac6-42bc-9d7e-29a6e48f1b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Data\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, TensorDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "303deef2-a879-4ac2-a4af-f803c663775b",
   "metadata": {},
   "source": [
    "Here, we will apply a funny method. Will divide data into seq_len chunks and learn batch by batch. This way, we will be doing teacher forcing. This is what we have done in 7. with batches. We also want to use closed loop. In another file, we have done that. But the learning architecture is one by one. I.e. we computed predictions for each data of length seq_len, calculated loss and updated which is not very efficient computationally. \n",
    "\n",
    "Here, we will do something in between. After calculating the first batch, we will use predicted values for few of the inputs of the next input. I believe it will be much more efficient than calculating next predictions one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e754552c-5588-49dd-baaa-ceed257bd8c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([850, 150, 1]) torch.Size([850, 1])\n"
     ]
    }
   ],
   "source": [
    "data = Data(0.01,1000,0.)\n",
    "X, Y = data[150]\n",
    "X = X.unsqueeze(-1)\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0b6845-434b-4f06-882e-41b7ad97c819",
   "metadata": {},
   "outputs": [],
   "source": [
    "def use_pred(in_data, prev_pred, i_1, i_2):\n",
    "    in_data[i_1,-i_2-1-i_1,:] = prev_pred[-i_2-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e44cc39-b362-408b-ad4b-6c3236b45e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = TensorDataset(X,Y)\n",
    "dl = DataLoader(ds,batch_size=100, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791fb6fd-29f0-4d5d-a712-a25c6cc8e1c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN_model(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hiddens,num_out=1):\n",
    "        super().__init__()\n",
    "        self.num_inputs = num_inputs\n",
    "        self.num_hiddens = num_hiddens\n",
    "        self.rnn = nn.RNN(num_inputs, num_hiddens, batch_first=True)\n",
    "        self.linear = nn.Linear(num_hiddens, num_out)\n",
    "    def forward(self, X, H):\n",
    "        state, H = self.rnn(X,H) \n",
    "        pred = self.linear(H[0]) #checked! H[0]=state[:,-1,:]\n",
    "        return pred # size = (batch_size, 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
